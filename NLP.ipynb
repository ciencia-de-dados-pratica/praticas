{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP\n",
    "\n",
    "Para saber mais sobre as informações deste notebook:\n",
    "\n",
    "[Tutorial retirado desse site - Brincando de nlp com spacy](https://leportella.com/pt-br/2017/11/30/brincando-de-nlp-com-spacy.html)\n",
    "\n",
    "[Spacy - site](https://spacy.io/api/)\n",
    "\n",
    "Para usar precisa primeiramente instalar usando o comando: **pip install spacy**\n",
    "\n",
    "Depois você instala o modelo que ja está treinado com palavras em português com o comando: **python -m spacy download pt **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente vamos fazer o modelo que usa a linguagem portugês"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora esse modelo vai nos ajudar a analisar textos em português.\n",
    "Vamos fazer uma frase simples usando o doc. Doc que é uma estutura que contém uma sequência de tokens e possui diversas informações sobre o texto. E um token é uma parte da estrutura podendo ser uma frase, uma palavra, uma pontuação ou até mesmo um espaço em branco neste exemplo eles vão ser palavras e pontuações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Ana, você comeu todo os dois bolos que eu te dei?')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o doc é uma estrutura interável então podemos fazer um for para pegar todos os tokens do doc.\n",
    "\n",
    "Vamos listar todos os tokens que existe no doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Ana, ,, você, comeu, todo, os, dois, bolos, que, eu, te, dei, ?]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver o spacy pode difenrenciar palavras de pontuações. Mas e se quisermos ver as strings e não os tokens?\n",
    "Existe o método .orth_ que nos ajuda nisso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ana',\n",
       " ',',\n",
       " 'você',\n",
       " 'comeu',\n",
       " 'todo',\n",
       " 'os',\n",
       " 'dois',\n",
       " 'bolos',\n",
       " 'que',\n",
       " 'eu',\n",
       " 'te',\n",
       " 'dei',\n",
       " '?']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.orth_ for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para pegar apenas as palavras vamos fazer um for para pegar todas as strings e restringir (por isso o if not) as pontuações que é reconhecido pelo método .is_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ana',\n",
       " 'você',\n",
       " 'comeu',\n",
       " 'todo',\n",
       " 'os',\n",
       " 'dois',\n",
       " 'bolos',\n",
       " 'que',\n",
       " 'eu',\n",
       " 'te',\n",
       " 'dei']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.orth_ for token in doc if not token.is_punct]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O spacy também pode reconhecer a similaridade entre as palavras. Usando o método similarity que avalia a similaridade semântica entre as palavras, quanto maior o valor, maior a similaridade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de analisar a similaridade precisamos pegar os tokens separadamente, por isso vamos fazer uma lista de tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [token for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos analisar a similaridade da palavra **você** token[1] e a palavra **eu** token[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15399452"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[1].similarity(tokens[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o valor esta positivo, significa que tem alguma similaridade entre **você** e **eu**. O que é verdade ja que as duas palavras são pronomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos analisar a similaridade da palavra **você** token[1] e **bolo** token[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.18722008"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[1].similarity(tokens[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o valor esta negativo não temos similaridade nenhuma entre essas palavras. O que esta certo também já que **você** é pronome enquanto **bolo** é substantivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos também ver a classificação gramatical de cada palavra da nossa frase. Vamos fazer um for pegando a string de cada token e vendo a classe dela com o método .pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ana', 'ADV'),\n",
       " (',', 'PUNCT'),\n",
       " ('você', 'PRON'),\n",
       " ('comeu', 'VERB'),\n",
       " ('todo', 'DET'),\n",
       " ('os', 'DET'),\n",
       " ('dois', 'NUM'),\n",
       " ('bolos', 'SYM'),\n",
       " ('que', 'PRON'),\n",
       " ('eu', 'PRON'),\n",
       " ('te', 'PRON'),\n",
       " ('dei', 'VERB'),\n",
       " ('?', 'PUNCT')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(token.orth_, token.pos_) for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver uma determinada classe gramatical, modificando nosso for para imprimir apenas quando o token.pos_ == verbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comeu', 'dei']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.orth_ for token in doc if token.pos_ == 'VERB']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para textos muito grandes analisar vários verbos com diferentes tempos verbais é muito difícil. Para resolver isso podemos usar um método que encontra a raiz desse verbos que ja estão conjugados. O método se chama .lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comer', 'dar']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.lemma_ for token in doc if token.pos_ == 'VERB']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim como podemos encontrar a raíz dos verbos, podemos também verificar se uma palvra é raiz de outra. Como por exemplo:\n",
    "\n",
    "    comer é raiz da palavra comeu?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(u'comer comeu')\n",
    "tokens = [token for token in doc]\n",
    "tokens[0].is_ancestor(tokens[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E por último não menos importante, podemos verificar as entidades que existe na frase, usando o método .ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Machado de Assis um dos melhores escritores do Brasil, foi o primeiro presidente da Academia Brasileira de Letras"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(u'Machado de Assis um dos melhores escritores do Brasil, foi o primeiro presidente da Academia Brasileira de Letras')\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Machado de Assis, Brasil, Academia Brasileira de Letras)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando o que são cada entidade, usamos o método .label_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Machado de Assis, 'PER'),\n",
       " (Brasil, 'LOC'),\n",
       " (Academia Brasileira de Letras, 'ORG')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(entity, entity.label_) for entity in doc.ents]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
